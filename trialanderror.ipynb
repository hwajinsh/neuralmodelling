{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tdlearning(alpha, stimuli, rewards, trials):\n",
    "    \"\"\"\n",
    "    Implements a temporal difference (TD) learning algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    - alpha: The learning rate for updating weights.\n",
    "    - stimuli: A sequence of stimuli presented over time.\n",
    "    - rewards: A sequence of rewards corresponding to the stimuli.\n",
    "    - trials: The number of trials for which learning occurs.\n",
    "\n",
    "    Returns:\n",
    "    - w (array): The learned weights for each stimulus.\n",
    "    - v (array): The value estimates for each stimulus over time.\n",
    "    - delta_v (array): The temporal differences between successive value estimates.\n",
    "    - delta (array): The TD error for all trials and time steps.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialise value estimates for each stimulus\n",
    "    v = np.zeros((len(stimuli))) \n",
    "    \n",
    "    # Initialise weights associated with each stimulus\n",
    "    w = np.zeros(len(stimuli)) \n",
    "    \n",
    "    # Initialise the TD error signal for all trials and time steps\n",
    "    delta = np.zeros([len(trials), len(stimuli)]) \n",
    "    \n",
    "    # Initialise temporal difference between successive value estimates\n",
    "    delta_v = np.zeros((len(stimuli))) \n",
    "    \n",
    "    # Iterate over the specified number of trials\n",
    "    for n in range(len(trials)):\n",
    "        # Iterate over time steps within the trial\n",
    "        for t in range(1, len(stimuli)):\n",
    "            # Compute the value estimate as the dot product of weights and stimuli history\n",
    "            v[t] = w[0:t] @ stimuli[t:0:-1][0]\n",
    "            \n",
    "            # Compute the temporal difference between consecutive value estimates\n",
    "            delta_v[t-1] = v[t] - v[t-1]\n",
    "            \n",
    "            # Compute the TD error, combining reward and temporal difference\n",
    "            delta[n, t] = rewards[t] + delta_v[t]\n",
    "            \n",
    "            # Update weights for all preceding time steps in the current trial\n",
    "            for tau in np.arange(t):\n",
    "                weight_update = w[tau] + alpha * delta[n, t] * stimuli[t-tau]\n",
    "                w[tau] = weight_update\n",
    "\n",
    "    return w, v, delta_v, delta\n",
    "\n",
    "# Parameters for timesteps (tau) and number of trials (t)\n",
    "\n",
    "tau = np.arange(250)\n",
    "t = np.arange(2000)\n",
    "\n",
    "# *** We might change this so that it would plot normally\n",
    "v_before = np.zeros(250)\n",
    "delta_v_before = np.zeros(250)\n",
    "delta_before = r\n",
    "\n",
    "alpha = 0.1  # learning rate\n",
    "\n",
    "# Initialise the stimulus array\n",
    "u = np.zeros((t, 1))\n",
    "u[100] = 1  # stimulus at time point 100\n",
    "\n",
    "# Initialise the reward array\n",
    "r = np.zeros(250)\n",
    "\n",
    "# Set r as Gaussian with its integral normalised to 2\n",
    "sigma = 5  # standard deviation for the Gaussian distribution\n",
    "r = gaussian_filter1d(r, sigma)\n",
    "\n",
    "# Normalise to sum to 2\n",
    "r *= 2 / np.sum(r)\n",
    "\n",
    "# call the temporal difference learning function\n",
    "w_after, v_after, delta_v_after, delta_after = tdlearning(alpha, u, r, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rs/csyk8bjx4zj6z782dmbhgw5w0000gn/T/ipykernel_46440/5033944.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a mesh grid for time points (x-axis) and trials (y-axis)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_weight_after\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_weight_after\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Data before and after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbefore_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_v_before\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_weight_before\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# stimulus, rewards, predictions, TD error, and weight changes before training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a mesh grid for time points (x-axis) and trials (y-axis)\n",
    "x, y = np.meshgrid(np.arange(delta_after.shape[1]), np.arange(delta_after.shape[0]))\n",
    "\n",
    "# Data before and after training\n",
    "before_training = [u, r, v_before, delta_v_before, delta_before]  # stimulus, rewards, predictions, TD error, and weight changes before training\n",
    "after_training = [u, r, v_after, delta_v_after, delta_after[-1, :]]  # same metrics after training\n",
    "\n",
    "def plottdlearning(before_training, after_training, x, y):\n",
    "    \"\"\"\n",
    "    Visualise the results of TD learning. \n",
    "    \"\"\"\n",
    "\n",
    "    labels = ['Stimulus (u)', 'Reward (r)', 'Prediction (v)', 'TD between Predictions (Δv)', 'TD Error (δ)']\n",
    "\n",
    "    # Plot 9.2 (A) TD error as a function of time within a trial, across trials\n",
    "    prediction_error = plt.figure()\n",
    "    \n",
    "    ax1 = prediction_error.add_subplot(111, projection='3d')\n",
    "    ax1.plot_surface(x, y, delta_after, antialiased=True, color='k', alpha=1)\n",
    "    ax1.set_xlabel('Time (t)')  # Label for the time axis\n",
    "    ax1.set_ylabel('Trials')  # Label for the trial axis\n",
    "    ax1.set_zlabel(\"TD Error (δ)\", labelpad=10)  # Label for the z-axis (temporal difference error)\n",
    "\n",
    "    # Adjust z-label position for readability\n",
    "    ax1.zaxis.label.set_position((0.05, 0.5))     \n",
    "\n",
    "    # Show Plot 9.2 (A)\n",
    "    plt.subplots_adjust(left=0.2, right=0.8, top=0.9, bottom=0.1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot 9.2. (B) stimulus, rewards, predictions, TD between predictions, and TD error before and after training\n",
    "    before_after = plt.figure()  \n",
    "\n",
    "    for i, (before, after, label) in enumerate(zip(before_training, after_training, labels)):\n",
    "        # Plot data before training (left column)\n",
    "        ax2 = before_after.add_subplot(5, 2, 2 * i + 1)  # Left column for data before training\n",
    "        ax2.plot(tau, before, color='black')  # Plot the data for each metric\n",
    "        ax2.set_ylabel(label, fontweight='bold')  # Add a y-axis label with the metric name\n",
    "        ax2.yaxis.label.set(rotation='horizontal', ha='right')  # Adjust label orientation\n",
    "        ax2.set_ylim(-1, 2.2)  # Set y-axis limits for consistency\n",
    "        ax2.grid(True, linestyle='--', alpha=0.6)  # Add gridlines for readability\n",
    "        if i == 0:\n",
    "            ax2.set_title('Before Training')  # Title for the left column\n",
    "\n",
    "        # Plot data after training (right column)\n",
    "        ax3 = before_after.add_subplot(5, 2, 2 * i + 2)  # Right column for data after training\n",
    "        ax3.plot(tau, after, color='black')  # Plot the data for each metric\n",
    "        ax3.set_ylim(-1, 2.2)  # Set y-axis limits for consistency\n",
    "        ax3.grid(True, linestyle='--', alpha=0.6)  # Add gridlines for readability\n",
    "        if i == 0:\n",
    "            ax3.set_title('After Training')  # Title for the right column\n",
    "\n",
    "    # Adjust layout to prevent overlaps between subplots\n",
    "    plt.subplots_adjust(left=0.1, right=0.9, top=0.95, bottom=0.05, hspace=0.5, wspace=0.3)\n",
    "\n",
    "    # Show Plot 9.2 (B)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Call the function to generate the plots\n",
    "plottdlearning(before_training, after_training, x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
